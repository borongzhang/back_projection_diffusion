{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP6GQNwnCrwz"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/grad/bzhang388/pisp/physics_aware_diffusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grad/bzhang388/anaconda3/envs/jaxflax/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZDKhSAGaCrk2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 02:47:44.068405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import utils\n",
    "import fstars \n",
    "import fstar_net\n",
    "import os\n",
    "\n",
    "from clu import metric_writers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "import h5py\n",
    "import natsort\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import geometric_transform\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from swirl_dynamics import templates\n",
    "from swirl_dynamics.lib import diffusion as dfn_lib\n",
    "from swirl_dynamics.lib import solvers as solver_lib\n",
    "from swirl_dynamics.projects import probabilistic_diffusion as dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.devices()\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U-O2msbGzEx"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4IpRYEJtGD-Q"
   },
   "outputs": [],
   "source": [
    "# Parameters for the computational task.\n",
    "\n",
    "#L = 4 # number of levels (even number)\n",
    "#s = 5 # leaf size\n",
    "#r = 3 # rank\n",
    "#\n",
    "## Discretization of Omega (n_eta * n_eta).\n",
    "#neta = (2**L)*s\n",
    "#\n",
    "## Number of sources/detectors (n_sc).\n",
    "## Discretization of the domain of alpha in polar coordinates (n_theta * n_rho).\n",
    "## For simplicity, these values are set equal (n_sc = n_theta = n_rho), facilitating computation.\n",
    "#nx = (2**L)*s\n",
    "neta = 60\n",
    "nx = 60\n",
    "# Standard deviation for the Gaussian blur.\n",
    "blur_sigma = 0.5\n",
    "\n",
    "# Number of training datapoints.\n",
    "NTRAIN = 21000\n",
    "\n",
    "# Number of testing datapoints.\n",
    "NTEST = 500\n",
    "\n",
    "# Total number\n",
    "NTOTAL = NTRAIN + NTEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../data/fastmri60'\n",
    "\n",
    "# Loading and preprocessing perturbation data (eta)\n",
    "with h5py.File(f'{name}/eta60.h5', 'r') as f:\n",
    "    # Read eta data, apply Gaussian blur, and reshape\n",
    "    eta_re = f[list(f.keys())[0]][:NTRAIN, :].reshape((-1,neta,neta))\n",
    "    blur_fn = lambda x: gaussian_filter(x, sigma=blur_sigma)\n",
    "    eta_re = np.stack([blur_fn(eta_re[i, :, :].T) for i in range(NTRAIN)]).astype('float32')\n",
    "    \n",
    "mean_eta = np.mean(eta_re, axis = 0)\n",
    "eta_re -= mean_eta\n",
    "std_eta = np.std(eta_re)\n",
    "eta_re /= std_eta\n",
    "\n",
    "# Loading and preprocessing scatter data (Lambda)\n",
    "with h5py.File(f'{name}/scatter60.h5', 'r') as f:\n",
    "    keys = natsort.natsorted(f.keys())\n",
    "\n",
    "    # Process real part of scatter data\n",
    "    tmp1 = f[keys[3]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[4]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[5]][:NTRAIN, :]\n",
    "    scatter_re = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "\n",
    "    # Process imaginary part of scatter data\n",
    "    tmp1 = f[keys[0]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[1]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[2]][:NTRAIN, :]\n",
    "    scatter_im = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "    \n",
    "    # Combine real and imaginary parts\n",
    "    scatter = np.stack((scatter_re, scatter_im), axis=-2).astype('float32')\n",
    "\n",
    "mean0, std0 = np.mean(scatter[:,:,:,0]), np.std(scatter[:,:,:,0])\n",
    "mean1, std1 = np.mean(scatter[:,:,:,1]), np.std(scatter[:,:,:,1])\n",
    "mean2, std2 = np.mean(scatter[:,:,:,2]), np.std(scatter[:,:,:,2])\n",
    "\n",
    "scatter[:,:,:,0] -= mean0\n",
    "scatter[:,:,:,0] /= std0\n",
    "scatter[:,:,:,1] -= mean1\n",
    "scatter[:,:,:,1] /= std1\n",
    "scatter[:,:,:,2] -= mean2\n",
    "scatter[:,:,:,2] /= std2\n",
    "\n",
    "# Clean up temporary variables to free memory\n",
    "del scatter_re, scatter_im, tmp1, tmp2, tmp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_train = eta_re.reshape(-1, neta, neta, 1)\n",
    "scatter_train = scatter.reshape(-1, nx**2, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid tf to use GPU memory\n",
    "\n",
    "batch_size = 16\n",
    "dict_data = {\"x\": eta_train}\n",
    "dict_data[\"cond\"] = {\"channel:scatter0\": scatter_train[:,:,:,0],\n",
    "                     \"channel:scatter1\": scatter_train[:,:,:,1],\n",
    "                     \"channel:scatter2\": scatter_train[:,:,:,2]}\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dict_data)\n",
    "dataset = dataset.shuffle(NTRAIN) \n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "dataset = dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZNUY5kQG9xd"
   },
   "source": [
    "The architecture is similar to the unconditional case. We provide additional args that specify how to resize the conditioning signal (in order to be compatible with the noisy sample for channel-wise concatenation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 02:48:59.596620: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 "
     ]
    }
   ],
   "source": [
    "r_index = utils.rotationindex(nx)\n",
    "cart_mat = utils.SparsePolarToCartesian(neta, nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fstars' from '/grad/bzhang388/pisp/physics_aware_diffusion/fstars.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(fstars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstarlist = [fstars.uncompressed_fstar( \n",
    "    nx = nx, \n",
    "    neta = neta,\n",
    "    cart_mat = cart_mat,\n",
    "    r_index = r_index\n",
    ") for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del r_index, cart_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fstar_net' from '/grad/bzhang388/pisp/physics_aware_diffusion/fstar_net.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(fstar_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_denoiser_model = fstar_net.PreconditionedDenoiser(\n",
    "    fstars=fstarlist,\n",
    "    out_channels=1,\n",
    "    squeeze_ratio=8,\n",
    "    cond_embed_iter=10, \n",
    "    noise_embed_dim=96, \n",
    "    num_conv=8,\n",
    "    num_feature=96, # multiples of 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xJFKb060GiRH"
   },
   "outputs": [],
   "source": [
    "diffusion_scheme = dfn_lib.Diffusion.create_variance_preserving(\n",
    "    sigma=dfn_lib.tangent_noise_schedule(),\n",
    "    data_std=1, # we always use normalized data\n",
    ")\n",
    "\n",
    "cond_model = dfn.DenoisingModel(\n",
    "    input_shape=(neta,neta,1),\n",
    "    cond_shape={\"channel:scatter0\": (nx**2,2),\n",
    "                \"channel:scatter1\": (nx**2,2),\n",
    "                \"channel:scatter2\": (nx**2,2)},\n",
    "    denoiser=cond_denoiser_model,\n",
    "    noise_sampling=dfn_lib.time_uniform_sampling(\n",
    "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
    "    ),\n",
    "    noise_weighting=dfn_lib.edm_weighting(data_std=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ekXD8PprGiM8"
   },
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "num_train_steps = 21000 * epochs // 16  #@param\n",
    "cond_workdir = os.path.abspath('') + \"/tmp/diffusion_uncompressed_fastmri_60\"\n",
    "initial_lr = 1e-5 #@param\n",
    "peak_lr = 1e-3 #@pawram\n",
    "warmup_steps = num_train_steps // 20  #@param\n",
    "end_lr = 1e-8 #@param\n",
    "ema_decay = 0.999  #@param\n",
    "ckpt_interval = 2000 #@param\n",
    "max_ckpt_to_keep = 3 #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 462415\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(666)\n",
    "params = cond_model.initialize(rng)\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "print('Number of trainable parameters:', param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: params/fstars_0/pre1, Parameters: 60\n",
      "Layer: params/fstars_0/pre2, Parameters: 60\n",
      "Layer: params/fstars_0/pre3, Parameters: 60\n",
      "Layer: params/fstars_0/pre4, Parameters: 60\n",
      "Layer: params/fstars_0/post1, Parameters: 60\n",
      "Layer: params/fstars_0/post2, Parameters: 60\n",
      "Layer: params/fstars_0/post3, Parameters: 60\n",
      "Layer: params/fstars_0/post4, Parameters: 60\n",
      "Layer: params/fstars_0/cos_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_0/sin_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_0/cos_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_0/sin_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_0/cos_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_0/sin_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_0/cos_kernel4, Parameters: 3600\n",
      "Layer: params/fstars_0/sin_kernel4, Parameters: 3600\n",
      "Layer: params/fstars_1/pre1, Parameters: 60\n",
      "Layer: params/fstars_1/pre2, Parameters: 60\n",
      "Layer: params/fstars_1/pre3, Parameters: 60\n",
      "Layer: params/fstars_1/pre4, Parameters: 60\n",
      "Layer: params/fstars_1/post1, Parameters: 60\n",
      "Layer: params/fstars_1/post2, Parameters: 60\n",
      "Layer: params/fstars_1/post3, Parameters: 60\n",
      "Layer: params/fstars_1/post4, Parameters: 60\n",
      "Layer: params/fstars_1/cos_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_1/sin_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_1/cos_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_1/sin_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_1/cos_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_1/sin_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_1/cos_kernel4, Parameters: 3600\n",
      "Layer: params/fstars_1/sin_kernel4, Parameters: 3600\n",
      "Layer: params/fstars_2/pre1, Parameters: 60\n",
      "Layer: params/fstars_2/pre2, Parameters: 60\n",
      "Layer: params/fstars_2/pre3, Parameters: 60\n",
      "Layer: params/fstars_2/pre4, Parameters: 60\n",
      "Layer: params/fstars_2/post1, Parameters: 60\n",
      "Layer: params/fstars_2/post2, Parameters: 60\n",
      "Layer: params/fstars_2/post3, Parameters: 60\n",
      "Layer: params/fstars_2/post4, Parameters: 60\n",
      "Layer: params/fstars_2/cos_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_2/sin_kernel1, Parameters: 3600\n",
      "Layer: params/fstars_2/cos_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_2/sin_kernel2, Parameters: 3600\n",
      "Layer: params/fstars_2/cos_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_2/sin_kernel3, Parameters: 3600\n",
      "Layer: params/fstars_2/cos_kernel4, Parameters: 3600\n",
      "Layer: params/fstars_2/sin_kernel4, Parameters: 3600\n",
      "Layer: params/InterpConvMerge_0/LayerNorm_0/scale, Parameters: 3\n",
      "Layer: params/InterpConvMerge_0/LayerNorm_0/bias, Parameters: 3\n",
      "Layer: params/InterpConvMerge_0/Conv_0/kernel, Parameters: 162\n",
      "Layer: params/InterpConvMerge_0/Conv_0/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_1/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_1/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_2/kernel, Parameters: 486\n",
      "Layer: params/InterpConvMerge_0/Conv_2/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_3/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_3/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_4/kernel, Parameters: 810\n",
      "Layer: params/InterpConvMerge_0/Conv_4/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_5/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_5/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_6/kernel, Parameters: 1134\n",
      "Layer: params/InterpConvMerge_0/Conv_6/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_7/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_7/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_8/kernel, Parameters: 1458\n",
      "Layer: params/InterpConvMerge_0/Conv_8/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_9/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_9/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_10/kernel, Parameters: 1782\n",
      "Layer: params/InterpConvMerge_0/Conv_10/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_11/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_11/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_12/kernel, Parameters: 2106\n",
      "Layer: params/InterpConvMerge_0/Conv_12/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_13/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_13/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_14/kernel, Parameters: 2430\n",
      "Layer: params/InterpConvMerge_0/Conv_14/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_15/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_15/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_16/kernel, Parameters: 2754\n",
      "Layer: params/InterpConvMerge_0/Conv_16/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_17/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_17/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_18/kernel, Parameters: 3078\n",
      "Layer: params/InterpConvMerge_0/Conv_18/bias, Parameters: 6\n",
      "Layer: params/InterpConvMerge_0/Conv_19/kernel, Parameters: 324\n",
      "Layer: params/InterpConvMerge_0/Conv_19/bias, Parameters: 6\n",
      "Layer: params/FourierEmbedding_0/Dense_0/kernel, Parameters: 18432\n",
      "Layer: params/FourierEmbedding_0/Dense_0/bias, Parameters: 192\n",
      "Layer: params/FourierEmbedding_0/Dense_1/kernel, Parameters: 18432\n",
      "Layer: params/FourierEmbedding_0/Dense_1/bias, Parameters: 96\n",
      "Layer: params/conv_in/kernel, Parameters: 55296\n",
      "Layer: params/conv_in/bias, Parameters: 96\n",
      "Layer: params/conv0/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv0/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv0/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv0/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv0/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv0/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv0/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv0/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv0/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv0/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv0/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv0/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv1/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv1/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv1/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv1/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv1/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv1/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv1/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv1/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv1/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv1/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv1/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv1/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv2/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv2/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv2/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv2/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv2/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv2/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv2/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv2/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv2/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv2/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv2/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv2/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv3/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv3/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv3/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv3/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv3/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv3/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv3/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv3/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv3/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv3/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv3/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv3/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv4/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv4/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv4/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv4/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv4/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv4/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv4/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv4/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv4/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv4/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv4/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv4/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv5/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv5/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv5/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv5/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv5/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv5/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv5/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv5/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv5/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv5/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv5/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv5/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv6/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv6/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv6/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv6/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv6/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv6/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv6/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv6/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv6/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv6/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv6/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv6/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv7/GroupNorm_0/scale, Parameters: 96\n",
      "Layer: params/conv7/GroupNorm_0/bias, Parameters: 96\n",
      "Layer: params/conv7/conv_squeeze/kernel, Parameters: 10368\n",
      "Layer: params/conv7/conv_squeeze/bias, Parameters: 12\n",
      "Layer: params/conv7/GroupNorm_1/scale, Parameters: 12\n",
      "Layer: params/conv7/GroupNorm_1/bias, Parameters: 12\n",
      "Layer: params/conv7/AdaptiveScale_0/Dense_0/kernel, Parameters: 2304\n",
      "Layer: params/conv7/AdaptiveScale_0/Dense_0/bias, Parameters: 24\n",
      "Layer: params/conv7/conv_expand/kernel, Parameters: 10368\n",
      "Layer: params/conv7/conv_expand/bias, Parameters: 96\n",
      "Layer: params/conv7/CombineResidualWithSkip_0/Dense_0/kernel, Parameters: 9216\n",
      "Layer: params/conv7/CombineResidualWithSkip_0/Dense_0/bias, Parameters: 96\n",
      "Layer: params/conv_out/kernel, Parameters: 864\n",
      "Layer: params/conv_out/bias, Parameters: 1\n",
      "Total parameters in the model: 462415\n"
     ]
    }
   ],
   "source": [
    "def count_params(params, parent_name=''):\n",
    "    \"\"\" Recursively count the number of parameters in the JAX model. \"\"\"\n",
    "    total_params = 0\n",
    "    for key, value in params.items():\n",
    "        layer_name = f\"{parent_name}/{key}\" if parent_name else key\n",
    "        if isinstance(value, dict):\n",
    "            # Recurse into nested dictionary\n",
    "            layer_params = count_params(value, layer_name)\n",
    "            total_params += layer_params\n",
    "        else:\n",
    "            # Assume value is a parameter array\n",
    "            layer_params = value.size\n",
    "            total_params += layer_params\n",
    "            print(f\"Layer: {layer_name}, Parameters: {layer_params}\")\n",
    "    return total_params\n",
    "\n",
    "total_parameters = count_params(params)\n",
    "print(f\"Total parameters in the model: {total_parameters}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19oJrFsjHCIZ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1DDpmV-zGiKW"
   },
   "outputs": [],
   "source": [
    "cond_trainer = dfn.DenoisingTrainer(\n",
    "    model=cond_model,\n",
    "    rng=jax.random.PRNGKey(666),\n",
    "    optimizer=optax.adam(\n",
    "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
    "            init_value=initial_lr,\n",
    "            peak_value=peak_lr,\n",
    "            warmup_steps=warmup_steps,\n",
    "            decay_steps=num_train_steps,\n",
    "            end_value=end_lr,\n",
    "        ),\n",
    "    ),\n",
    "    ema_decay=ema_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5630e693634963aab338dc9376487b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157500 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "templates.run_train(\n",
    "    train_dataloader=dataset,\n",
    "    trainer=cond_trainer,\n",
    "    workdir=cond_workdir,\n",
    "    total_train_steps=num_train_steps,\n",
    "    metric_writer=metric_writers.create_default_writer(\n",
    "        cond_workdir, asynchronous=False\n",
    "    ),\n",
    "    metric_aggregation_steps = 100,\n",
    "    callbacks=(\n",
    "        templates.TqdmProgressBar(\n",
    "            total_train_steps=num_train_steps,\n",
    "            train_monitors=(\"train_loss\",),\n",
    "        ),\n",
    "        templates.TrainStateCheckpoint(\n",
    "            base_dir=cond_workdir,\n",
    "            options=ocp.CheckpointManagerOptions( \n",
    "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS0m_f0CHR5i"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8RHlke6pGiHx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n"
     ]
    }
   ],
   "source": [
    "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
    "    f\"{cond_workdir}/checkpoints\", step=None\n",
    ")\n",
    "\n",
    "# Construct the inference function\n",
    "cond_denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
    "    trained_state, use_ema=True, denoiser=cond_denoiser_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qnaFzOjOHOu4"
   },
   "outputs": [],
   "source": [
    "cond_sampler = dfn_lib.SdeSampler(\n",
    "    input_shape=(neta,neta,1),\n",
    "    integrator=solver_lib.EulerMaruyama(),\n",
    "    tspan=dfn_lib.exponential_noise_decay(diffusion_scheme, num_steps=256, end_sigma=1e-3,),\n",
    "    scheme=diffusion_scheme,\n",
    "    denoise_fn=cond_denoise_fn,\n",
    "    guidance_transforms=(),\n",
    "    apply_denoise_at_end=True,\n",
    "    return_full_paths=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lYF1OUEHZFM"
   },
   "source": [
    "We again JIT the generate function for the sake of faster repeated sampling calls. Here we employ `functools.partial` to specify `num_samples=5`, making it easier to vectorize across the batch dimension with `jax.vmap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mT_rLzdgHOsm"
   },
   "outputs": [],
   "source": [
    "num_samples_per_cond = 1\n",
    "\n",
    "generate = jax.jit(\n",
    "    functools.partial(cond_sampler.generate, num_samples_per_cond)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTEST = 500 # Change it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_9TfCMSHd3P"
   },
   "source": [
    "Loading a test batch of conditions with 4 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../data/fastmri60'\n",
    "\n",
    "# Loading and preprocessing perturbation data (eta)\n",
    "with h5py.File(f'{name}/eta60.h5', 'r') as f:\n",
    "    # Read eta data, apply Gaussian blur, and reshape\n",
    "    eta_re = f[list(f.keys())[0]][-NTEST:, :].reshape(-1, neta, neta)\n",
    "    blur_fn = lambda x: gaussian_filter(x, sigma=blur_sigma)\n",
    "    eta_re = np.stack([blur_fn(img.T) for img in eta_re]).astype('float32')\n",
    "\n",
    "# Loading and preprocessing scatter data (Lambda)\n",
    "with h5py.File(f'{name}/scatter60.h5', 'r') as f:\n",
    "    keys = natsort.natsorted(f.keys())\n",
    "\n",
    "    # Process real part of scatter data\n",
    "    tmp1 = f[keys[3]][-NTEST:, :]\n",
    "    tmp2 = f[keys[4]][-NTEST:, :]\n",
    "    tmp3 = f[keys[5]][-NTEST:, :]\n",
    "    scatter_re = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "\n",
    "    # Process imaginary part of scatter data\n",
    "    tmp1 = f[keys[0]][-NTEST:, :]\n",
    "    tmp2 = f[keys[1]][-NTEST:, :]\n",
    "    tmp3 = f[keys[2]][-NTEST:, :]\n",
    "    scatter_im = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "    \n",
    "    # Combine real and imaginary parts\n",
    "    scatter = np.stack((scatter_re, scatter_im), axis=-2).astype('float32')\n",
    "    \n",
    "scatter[:,:,:,0] -= mean0\n",
    "scatter[:,:,:,0] /= std0\n",
    "scatter[:,:,:,1] -= mean1\n",
    "scatter[:,:,:,1] /= std1\n",
    "scatter[:,:,:,2] -= mean2\n",
    "scatter[:,:,:,2] /= std2\n",
    "\n",
    "# Clean up temporary variables to free memory\n",
    "del scatter_re, scatter_im, tmp1, tmp2, tmp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_test = eta_re.reshape(-1, neta, neta, 1)\n",
    "scatter_test = scatter.reshape(-1, nx**2, 2, 3) \n",
    "#scatter_test = np.swapaxes(scatter_test,1,2).reshape(-1, 6400, 2, 3)\n",
    "#c = 0.4\n",
    "#scatter_test += np.random.normal(0,c,size=scatter_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_test = 20\n",
    "dict_data_test = {}\n",
    "dict_data_test[\"cond\"] = {\"channel:scatter0\": scatter_test[:,:,:,0],\n",
    "                          \"channel:scatter1\": scatter_test[:,:,:,1],\n",
    "                          \"channel:scatter2\": scatter_test[:,:,:,2]}\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(dict_data_test)\n",
    "dataset_test = dataset_test.batch(batch_size_test)\n",
    "dataset_test = dataset_test.prefetch(tf.data.AUTOTUNE)\n",
    "dataset_test = dataset_test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 07:31:22.362990: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "eta_pred = np.zeros((NTEST, num_samples_per_cond, neta, neta, 1))\n",
    "\n",
    "b = 0\n",
    "for batch in dataset_test:\n",
    "    print(b)\n",
    "    cond_samples = jax.device_get(jax.vmap(generate, in_axes=(0, 0, None))(\n",
    "        jax.random.split(jax.random.PRNGKey(68), batch_size_test),\n",
    "        batch[\"cond\"],\n",
    "        None,  # Guidance inputs = None since no guidance transforms involved\n",
    "    ))\n",
    "    eta_pred[b*batch_size_test:(b+1)*batch_size_test,:,:,:,:] = cond_samples*std_eta+mean_eta[:, :, jnp.newaxis]\n",
    "    b += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of validation relative l2 error: 0.05363113087343309\n",
      "Median of validation relative l2 error: 0.054492172578428255\n",
      "Min of validation relative l2 error: 0.02654575802626506\n",
      "Max of validation relative l2 error: 0.10394141285320327\n",
      "Standard deviation of validation relative l2 errors: 0.013645110504661438\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(NTEST):\n",
    "    for j in range(num_samples_per_cond):\n",
    "        errors.append(np.linalg.norm(eta_test[i,:,:,0]-eta_pred[i,0,:,:,0])/np.linalg.norm(eta_test[i,:,:,0]))\n",
    "        \n",
    "print('Mean of validation relative l2 error:', np.mean(errors))\n",
    "print('Median of validation relative l2 error:', np.median(errors))\n",
    "print('Min of validation relative l2 error:', np.min(errors))\n",
    "print('Max of validation relative l2 error:', np.max(errors))\n",
    "print('Standard deviation of validation relative l2 errors:', np.std(errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5py.File(\"results_diffusion_uncompressed_squares_final.h5\", \"w\") as f:\n",
    "#    f.create_dataset('eta', data=eta_test)\n",
    "#    f.create_dataset('eta_pred', data=eta_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5py.File(\"results_diffusion_uncompressed_squares.h5\", \"w\") as f:\n",
    "#    f.create_dataset('eta', data=eta_test)\n",
    "#    f.create_dataset('eta_pred', data=eta_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "last_runtime": {
    "build_target": "//learning/grp/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1eA8hF0r-tUgIX-miyPgPkzH80WjzCarp",
     "timestamp": 1707268348992
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 11 jaxflax",
   "language": "python",
   "name": "jaxflax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
